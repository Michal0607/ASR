{
  "best_metric": 0.0935483870967742,
  "best_model_checkpoint": "./results/checkpoint-133",
  "epoch": 0.9953227315247896,
  "eval_steps": 500,
  "global_step": 133,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014967259120673527,
      "grad_norm": 1.089234471321106,
      "learning_rate": 9.849624060150376e-06,
      "loss": 2.1813,
      "step": 2
    },
    {
      "epoch": 0.029934518241347054,
      "grad_norm": 1.1518748998641968,
      "learning_rate": 9.699248120300752e-06,
      "loss": 2.186,
      "step": 4
    },
    {
      "epoch": 0.04490177736202058,
      "grad_norm": 1.1430718898773193,
      "learning_rate": 9.54887218045113e-06,
      "loss": 1.9999,
      "step": 6
    },
    {
      "epoch": 0.05986903648269411,
      "grad_norm": 1.141430139541626,
      "learning_rate": 9.398496240601505e-06,
      "loss": 2.0564,
      "step": 8
    },
    {
      "epoch": 0.07483629560336763,
      "grad_norm": 1.208855390548706,
      "learning_rate": 9.24812030075188e-06,
      "loss": 2.1184,
      "step": 10
    },
    {
      "epoch": 0.08980355472404115,
      "grad_norm": 1.2313967943191528,
      "learning_rate": 9.097744360902256e-06,
      "loss": 2.0871,
      "step": 12
    },
    {
      "epoch": 0.10477081384471469,
      "grad_norm": 1.5013421773910522,
      "learning_rate": 8.947368421052632e-06,
      "loss": 2.3628,
      "step": 14
    },
    {
      "epoch": 0.11973807296538821,
      "grad_norm": NaN,
      "learning_rate": 8.87218045112782e-06,
      "loss": 2.0988,
      "step": 16
    },
    {
      "epoch": 0.13470533208606175,
      "grad_norm": 1.3105190992355347,
      "learning_rate": 8.721804511278195e-06,
      "loss": 1.8837,
      "step": 18
    },
    {
      "epoch": 0.14967259120673526,
      "grad_norm": 1.3105343580245972,
      "learning_rate": 8.571428571428571e-06,
      "loss": 2.0514,
      "step": 20
    },
    {
      "epoch": 0.1646398503274088,
      "grad_norm": 1.7773255109786987,
      "learning_rate": 8.421052631578948e-06,
      "loss": 2.2092,
      "step": 22
    },
    {
      "epoch": 0.1796071094480823,
      "grad_norm": 1.377750039100647,
      "learning_rate": 8.270676691729324e-06,
      "loss": 1.7392,
      "step": 24
    },
    {
      "epoch": 0.19457436856875585,
      "grad_norm": 1.5453155040740967,
      "learning_rate": 8.1203007518797e-06,
      "loss": 1.9178,
      "step": 26
    },
    {
      "epoch": 0.20954162768942938,
      "grad_norm": 1.3991641998291016,
      "learning_rate": 7.969924812030075e-06,
      "loss": 2.1674,
      "step": 28
    },
    {
      "epoch": 0.2245088868101029,
      "grad_norm": 1.2352083921432495,
      "learning_rate": 7.81954887218045e-06,
      "loss": 2.0326,
      "step": 30
    },
    {
      "epoch": 0.23947614593077643,
      "grad_norm": 1.208261489868164,
      "learning_rate": 7.669172932330828e-06,
      "loss": 1.7143,
      "step": 32
    },
    {
      "epoch": 0.25444340505144997,
      "grad_norm": 0.7890806794166565,
      "learning_rate": 7.518796992481203e-06,
      "loss": 1.7196,
      "step": 34
    },
    {
      "epoch": 0.2694106641721235,
      "grad_norm": NaN,
      "learning_rate": 7.4436090225563915e-06,
      "loss": 1.7935,
      "step": 36
    },
    {
      "epoch": 0.284377923292797,
      "grad_norm": 1.153544306755066,
      "learning_rate": 7.368421052631579e-06,
      "loss": 1.9311,
      "step": 38
    },
    {
      "epoch": 0.2993451824134705,
      "grad_norm": 0.953227162361145,
      "learning_rate": 7.218045112781955e-06,
      "loss": 1.9602,
      "step": 40
    },
    {
      "epoch": 0.31431244153414406,
      "grad_norm": 0.7313887476921082,
      "learning_rate": 7.067669172932331e-06,
      "loss": 1.8828,
      "step": 42
    },
    {
      "epoch": 0.3292797006548176,
      "grad_norm": 4.708414554595947,
      "learning_rate": 6.917293233082707e-06,
      "loss": 1.7566,
      "step": 44
    },
    {
      "epoch": 0.34424695977549113,
      "grad_norm": 0.7505918145179749,
      "learning_rate": 6.766917293233083e-06,
      "loss": 1.8083,
      "step": 46
    },
    {
      "epoch": 0.3592142188961646,
      "grad_norm": 0.6896936893463135,
      "learning_rate": 6.616541353383459e-06,
      "loss": 1.5466,
      "step": 48
    },
    {
      "epoch": 0.37418147801683815,
      "grad_norm": 0.6537414193153381,
      "learning_rate": 6.466165413533835e-06,
      "loss": 1.5712,
      "step": 50
    },
    {
      "epoch": 0.3891487371375117,
      "grad_norm": 1.0803872346878052,
      "learning_rate": 6.31578947368421e-06,
      "loss": 2.0726,
      "step": 52
    },
    {
      "epoch": 0.40411599625818523,
      "grad_norm": 0.6865984201431274,
      "learning_rate": 6.165413533834587e-06,
      "loss": 1.9389,
      "step": 54
    },
    {
      "epoch": 0.41908325537885877,
      "grad_norm": 0.9476302266120911,
      "learning_rate": 6.015037593984962e-06,
      "loss": 1.9055,
      "step": 56
    },
    {
      "epoch": 0.43405051449953225,
      "grad_norm": 1.3154524564743042,
      "learning_rate": 5.864661654135339e-06,
      "loss": 1.9104,
      "step": 58
    },
    {
      "epoch": 0.4490177736202058,
      "grad_norm": 0.8676474094390869,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 1.8201,
      "step": 60
    },
    {
      "epoch": 0.4639850327408793,
      "grad_norm": 0.8669660687446594,
      "learning_rate": 5.56390977443609e-06,
      "loss": 1.7277,
      "step": 62
    },
    {
      "epoch": 0.47895229186155286,
      "grad_norm": 1.1879669427871704,
      "learning_rate": 5.413533834586467e-06,
      "loss": 1.7779,
      "step": 64
    },
    {
      "epoch": 0.4939195509822264,
      "grad_norm": 0.8076193928718567,
      "learning_rate": 5.263157894736842e-06,
      "loss": 1.8176,
      "step": 66
    },
    {
      "epoch": 0.5088868101028999,
      "grad_norm": 0.756158709526062,
      "learning_rate": 5.112781954887218e-06,
      "loss": 1.7241,
      "step": 68
    },
    {
      "epoch": 0.5238540692235735,
      "grad_norm": 0.7134416699409485,
      "learning_rate": 4.962406015037594e-06,
      "loss": 1.7052,
      "step": 70
    },
    {
      "epoch": 0.538821328344247,
      "grad_norm": 0.9839416742324829,
      "learning_rate": 4.81203007518797e-06,
      "loss": 1.8328,
      "step": 72
    },
    {
      "epoch": 0.5537885874649204,
      "grad_norm": 0.950846791267395,
      "learning_rate": 4.661654135338346e-06,
      "loss": 2.0557,
      "step": 74
    },
    {
      "epoch": 0.568755846585594,
      "grad_norm": 1.9204148054122925,
      "learning_rate": 4.511278195488722e-06,
      "loss": 2.0734,
      "step": 76
    },
    {
      "epoch": 0.5837231057062675,
      "grad_norm": 0.6709758639335632,
      "learning_rate": 4.360902255639098e-06,
      "loss": 1.6273,
      "step": 78
    },
    {
      "epoch": 0.598690364826941,
      "grad_norm": 3.133845806121826,
      "learning_rate": 4.210526315789474e-06,
      "loss": 1.7305,
      "step": 80
    },
    {
      "epoch": 0.6136576239476146,
      "grad_norm": 0.8419471383094788,
      "learning_rate": 4.06015037593985e-06,
      "loss": 1.8668,
      "step": 82
    },
    {
      "epoch": 0.6286248830682881,
      "grad_norm": 0.7434635162353516,
      "learning_rate": 3.909774436090225e-06,
      "loss": 1.7906,
      "step": 84
    },
    {
      "epoch": 0.6435921421889617,
      "grad_norm": 0.9052684307098389,
      "learning_rate": 3.7593984962406014e-06,
      "loss": 1.8848,
      "step": 86
    },
    {
      "epoch": 0.6585594013096352,
      "grad_norm": 0.7852833867073059,
      "learning_rate": 3.6090225563909775e-06,
      "loss": 1.706,
      "step": 88
    },
    {
      "epoch": 0.6735266604303087,
      "grad_norm": 0.9416821599006653,
      "learning_rate": 3.4586466165413535e-06,
      "loss": 1.654,
      "step": 90
    },
    {
      "epoch": 0.6884939195509823,
      "grad_norm": 0.8084867000579834,
      "learning_rate": 3.3082706766917295e-06,
      "loss": 1.5636,
      "step": 92
    },
    {
      "epoch": 0.7034611786716558,
      "grad_norm": 0.8821154832839966,
      "learning_rate": 3.157894736842105e-06,
      "loss": 1.8122,
      "step": 94
    },
    {
      "epoch": 0.7184284377923292,
      "grad_norm": 1.3252593278884888,
      "learning_rate": 3.007518796992481e-06,
      "loss": 1.8682,
      "step": 96
    },
    {
      "epoch": 0.7333956969130028,
      "grad_norm": 0.889886200428009,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 1.6404,
      "step": 98
    },
    {
      "epoch": 0.7483629560336763,
      "grad_norm": 0.7830886840820312,
      "learning_rate": 2.7067669172932333e-06,
      "loss": 1.7943,
      "step": 100
    },
    {
      "epoch": 0.7633302151543498,
      "grad_norm": 0.9217758178710938,
      "learning_rate": 2.556390977443609e-06,
      "loss": 1.7245,
      "step": 102
    },
    {
      "epoch": 0.7782974742750234,
      "grad_norm": 0.8510028719902039,
      "learning_rate": 2.406015037593985e-06,
      "loss": 1.6607,
      "step": 104
    },
    {
      "epoch": 0.7932647333956969,
      "grad_norm": 0.9884044528007507,
      "learning_rate": 2.255639097744361e-06,
      "loss": 1.7414,
      "step": 106
    },
    {
      "epoch": 0.8082319925163705,
      "grad_norm": 1.0074306726455688,
      "learning_rate": 2.105263157894737e-06,
      "loss": 1.717,
      "step": 108
    },
    {
      "epoch": 0.823199251637044,
      "grad_norm": 1.2572351694107056,
      "learning_rate": 1.9548872180451127e-06,
      "loss": 1.7639,
      "step": 110
    },
    {
      "epoch": 0.8381665107577175,
      "grad_norm": 0.7495412826538086,
      "learning_rate": 1.8045112781954887e-06,
      "loss": 1.5166,
      "step": 112
    },
    {
      "epoch": 0.8531337698783911,
      "grad_norm": 1.5896035432815552,
      "learning_rate": 1.6541353383458648e-06,
      "loss": 1.8078,
      "step": 114
    },
    {
      "epoch": 0.8681010289990645,
      "grad_norm": 0.8271892666816711,
      "learning_rate": 1.5037593984962406e-06,
      "loss": 1.694,
      "step": 116
    },
    {
      "epoch": 0.883068288119738,
      "grad_norm": 1.2829703092575073,
      "learning_rate": 1.3533834586466167e-06,
      "loss": 1.9252,
      "step": 118
    },
    {
      "epoch": 0.8980355472404116,
      "grad_norm": 2.1078526973724365,
      "learning_rate": 1.2030075187969925e-06,
      "loss": 1.9285,
      "step": 120
    },
    {
      "epoch": 0.9130028063610851,
      "grad_norm": 1.1323796510696411,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 1.8824,
      "step": 122
    },
    {
      "epoch": 0.9279700654817586,
      "grad_norm": 1.23121178150177,
      "learning_rate": 9.022556390977444e-07,
      "loss": 1.465,
      "step": 124
    },
    {
      "epoch": 0.9429373246024322,
      "grad_norm": 0.8778302073478699,
      "learning_rate": 7.518796992481203e-07,
      "loss": 1.6905,
      "step": 126
    },
    {
      "epoch": 0.9579045837231057,
      "grad_norm": 0.8041294813156128,
      "learning_rate": 6.015037593984962e-07,
      "loss": 1.8147,
      "step": 128
    },
    {
      "epoch": 0.9728718428437793,
      "grad_norm": 0.8210989236831665,
      "learning_rate": 4.511278195488722e-07,
      "loss": 1.6837,
      "step": 130
    },
    {
      "epoch": 0.9878391019644528,
      "grad_norm": 0.9266697764396667,
      "learning_rate": 3.007518796992481e-07,
      "loss": 2.0249,
      "step": 132
    },
    {
      "epoch": 0.9953227315247896,
      "eval_loss": 1.2887438535690308,
      "eval_runtime": 122.5571,
      "eval_samples_per_second": 0.18,
      "eval_steps_per_second": 0.016,
      "eval_wer": 0.0935483870967742,
      "step": 133
    }
  ],
  "logging_steps": 2,
  "max_steps": 133,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.5422067253248e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
